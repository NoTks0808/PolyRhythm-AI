import { DrumInstrument, DrumKit, GeneratedPattern } from '../types';

// ç®€å•ç²—æš´çš„è·¯å¾„ä¿®æ­£ï¼šåªç”¨ /samples/
// è¿™ç§å†™æ³•åŒæ—¶å…¼å®¹æœ¬åœ° (localhost:3000/samples/...) å’Œ GitHub Pages (å¦‚æœä¸æ”¹ base)
// å¦‚æœä½  Vite é…ç½®äº† baseï¼Œè¿™é‡Œä¼šè‡ªåŠ¨é€‚é…
const BASE_PATH = import.meta.env.BASE_URL.endsWith('/') ? import.meta.env.BASE_URL : `${import.meta.env.BASE_URL}/`;

const LOCAL_SAMPLE_MAP: Record<DrumInstrument, string> = {
  [DrumInstrument.KICK]: `${BASE_PATH}samples/kick.wav`,
  [DrumInstrument.SNARE]: `${BASE_PATH}samples/snare.wav`,
  [DrumInstrument.HIHAT_CLOSED]: `${BASE_PATH}samples/hatClosed.wav`,
  [DrumInstrument.HIHAT_OPEN]: `${BASE_PATH}samples/hatOpen.wav`,
  [DrumInstrument.TOM_LOW]: `${BASE_PATH}samples/tomLow.wav`,
  [DrumInstrument.TOM_HIGH]: `${BASE_PATH}samples/tomHigh.wav`,
  [DrumInstrument.CRASH]: `${BASE_PATH}samples/crash.wav`,
  [DrumInstrument.RIDE]: `${BASE_PATH}samples/ride.wav`,
};

class AudioEngine {
  private ctx: AudioContext | null = null;
  private masterChain: AudioNode | null = null;
  private buffers: Map<DrumInstrument, AudioBuffer> = new Map();
  private isLoaded: boolean = false;
  
  // é¿å…é‡å¤åŠ è½½çš„é”
  private isLoadingSamples: boolean = false;

  private noiseBuffer: AudioBuffer | null = null;
  private distortionCurve: Float32Array | null = null;
  private softClipCurve: Float32Array | null = null;
  private currentKit: DrumKit = DrumKit.ACOUSTIC;

  constructor() {}

  public async setKit(kit: DrumKit) {
    this.currentKit = kit;
    // åˆ‡æ¢åˆ°åŸå£°é¼“æ—¶ï¼Œå¦‚æœè¿˜æ²¡åŠ è½½ï¼Œå°è¯•åŠ è½½ï¼ˆä¸é˜»å¡ï¼‰
    if (kit === DrumKit.ACOUSTIC && !this.isLoaded) {
        this.loadLocalSamples();
    }
  }

  public getKit(): DrumKit { return this.currentKit; }
  public getCurrentTime(): number { return this.ctx?.currentTime || 0; }

  // ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šInit ç»ä¸ç­‰å¾…é‡‡æ ·åŠ è½½
  public async init() {
    if (!this.ctx) {
      console.log("[AudioEngine] åˆå§‹åŒ–æ ¸å¿ƒ...");
      const CtxClass = window.AudioContext || (window as any).webkitAudioContext;
      this.ctx = new CtxClass();
      
      const safetyFilter = this.ctx.createBiquadFilter();
      safetyFilter.type = 'highpass'; safetyFilter.frequency.value = 30;
      this.createSoftClipCurve();
      const softClipper = this.ctx.createWaveShaper();
      if (this.softClipCurve) softClipper.curve = this.softClipCurve as any;
      softClipper.oversample = '4x';
      const masterGain = this.ctx.createGain();
      masterGain.gain.value = 0.8; 

      safetyFilter.connect(softClipper); softClipper.connect(masterGain); masterGain.connect(this.ctx.destination);
      this.masterChain = safetyFilter;
      
      // åˆæˆå™¨èµ„æºç«‹åˆ»å‡†å¤‡å¥½
      this.createNoiseBuffer();
      this.createDistortionCurve(400); 
    }

    // å¼ºåŠ›å”¤é†’
    if (this.ctx.state === 'suspended') {
      console.log("[AudioEngine] å°è¯•å”¤é†’...");
      await this.ctx.resume();
    }
    
    // ğŸ”¥ å…³é”®ï¼šåœ¨è¿™é‡Œå¯åŠ¨åŠ è½½ï¼Œä½†ã€ä¸ä½¿ç”¨ awaitã€‘
    // è¿™æ · init ä¼šç«‹åˆ»å®Œæˆï¼ŒApp.tsx é‡Œçš„ await audio.init() ä¹Ÿä¼šç«‹åˆ»é€šè¿‡
    // ç”µå­é¼“å’Œå·¥ä¸šé¼“é©¬ä¸Šå°±èƒ½ç”¨ï¼
    if (!this.isLoaded && !this.isLoadingSamples) {
        this.loadLocalSamples(); 
    }
  }

  private async loadLocalSamples() {
    if (this.isLoaded || this.isLoadingSamples) return;
    this.isLoadingSamples = true;

    console.log("[AudioEngine] åå°å¼€å§‹ä¸‹è½½é‡‡æ ·...");
    const promises = Object.entries(LOCAL_SAMPLE_MAP).map(async ([inst, path]) => {
        try {
            // é˜²ç¼“å­˜
            const fetchPath = `${path}?t=${Date.now()}`; 
            const response = await fetch(fetchPath);
            if (!response.ok) throw new Error(`HTTP ${response.status}`);
            const arrayBuffer = await response.arrayBuffer();
            if (this.ctx) {
                const audioBuffer = await this.ctx.decodeAudioData(arrayBuffer);
                this.buffers.set(inst as DrumInstrument, audioBuffer);
            }
        } catch (e: any) {
            console.warn(`âš ï¸ é‡‡æ ·åŠ è½½å¤±è´¥ [${inst}]:`, e.message || e);
        }
    });

    await Promise.all(promises);
    this.isLoaded = true;
    this.isLoadingSamples = false;
    console.log(`[AudioEngine] é‡‡æ ·åŠ è½½ç»“æŸã€‚å¯ç”¨: ${this.buffers.size}/8`);
  }

  // ... (èµ„æºç”Ÿæˆå‡½æ•°ä¿æŒä¸å˜) ...
  private createSoftClipCurve() { const n=65536; const c=new Float32Array(n); for(let i=0;i<n;i++) c[i]=Math.tanh((i*2)/n-1); this.softClipCurve=c; }
  private createNoiseBuffer() { if(!this.ctx)return; const b=this.ctx.createBuffer(1,this.ctx.sampleRate*2,this.ctx.sampleRate); const d=b.getChannelData(0); for(let i=0;i<d.length;i++) d[i]=Math.random()*2-1; this.noiseBuffer=b; }
  private createDistortionCurve(amount: number) { const n=44100; const c=new Float32Array(n); const deg=Math.PI/180; for(let i=0;i<n;++i){const x=i*2/n-1;c[i]=(3+amount)*x*20*deg/(Math.PI+amount*Math.abs(x));} this.distortionCurve=c; }

  private scheduleNoteGraph(ctx: BaseAudioContext, destination: AudioNode, instrument: DrumInstrument, time: number, velocity: number, kit: DrumKit) {
    const safeTime = Math.max(ctx.currentTime, time);

    // 1. ç”µå­/å·¥ä¸šé¼“ -> è¿™é‡Œçš„èµ„æºåœ¨ init() é‡Œå·²ç»å¥½äº†ï¼Œåº”è¯¥ 100% èƒ½å“
    if (kit === DrumKit.ELECTRONIC || kit === DrumKit.INDUSTRIAL) {
        this.synthesizeDrum(ctx, destination, instrument, safeTime, velocity, kit);
        return;
    }

    // 2. åŸå£°é¼“ -> ä¾èµ–å¼‚æ­¥åŠ è½½çš„ buffer
    const buffer = this.buffers.get(instrument);
    if (!buffer) {
        // å¦‚æœæ–‡ä»¶è¿˜æ²¡ä¸‹å¥½ï¼Œæš‚æ—¶ä¸å“ï¼Œä¹Ÿä¸æŠ¥é”™
        return;
    }

    const source = ctx.createBufferSource();
    source.buffer = buffer;
    if (instrument !== DrumInstrument.KICK && instrument !== DrumInstrument.SNARE) {
        source.detune.value = (Math.random() * 20) - 10;
    }
    const envGain = ctx.createGain();
    const targetGain = velocity * velocity; 
    envGain.gain.setValueAtTime(0, safeTime);
    envGain.gain.linearRampToValueAtTime(targetGain, safeTime + 0.002);
    envGain.gain.exponentialRampToValueAtTime(0.001, safeTime + 3.0); 
    source.connect(envGain); envGain.connect(destination);
    source.start(safeTime);
  }

  private synthesizeDrum(ctx: BaseAudioContext, destination: AudioNode, inst: DrumInstrument, time: number, vel: number, kit: DrumKit) {
    // å·¥ä¸šé£/ç”µå­é£ åˆæˆé€»è¾‘ (ä¿æŒä¹‹å‰å¯ç”¨çš„ç‰ˆæœ¬)
    const isIndustrial = kit === DrumKit.INDUSTRIAL;
    const osc = ctx.createOscillator(); 
    const noise = ctx.createBufferSource();
    if (this.noiseBuffer) noise.buffer = this.noiseBuffer; // noiseBuffer åœ¨ init æ—¶åˆ›å»ºï¼Œè‚¯å®šæœ‰
    const masterGain = ctx.createGain(); 
    
    let chainOut: AudioNode = masterGain;

    if (isIndustrial) {
        const dist = ctx.createWaveShaper(); if (this.distortionCurve) dist.curve = this.distortionCurve as any; dist.oversample = '4x';
        const filter = ctx.createBiquadFilter(); filter.type = 'lowpass'; filter.frequency.value = 3000 + (vel * 2000);
        const comp = ctx.createDynamicsCompressor(); comp.threshold.value = -30; comp.ratio.value = 12;
        masterGain.disconnect(); masterGain.connect(dist); dist.connect(filter); filter.connect(comp); chainOut = comp;
    } else {
        const comp = ctx.createDynamicsCompressor(); comp.threshold.value = -20; comp.ratio.value = 4; comp.attack.value = 0.001;
        masterGain.disconnect(); masterGain.connect(comp); chainOut = comp;
    }
    
    chainOut.connect(destination);
    const baseVol = vel;

    // ç®€å•çš„åˆæˆéŸ³è‰²æ˜ å°„
    switch (inst) {
        case DrumInstrument.KICK:
            osc.frequency.setValueAtTime(isIndustrial ? 120 : 150, time); osc.frequency.exponentialRampToValueAtTime(40, time + 0.5);
            masterGain.gain.setValueAtTime(baseVol, time); masterGain.gain.exponentialRampToValueAtTime(0.001, time + 0.5);
            osc.connect(masterGain); osc.start(time); osc.stop(time + 0.5); break;
        case DrumInstrument.SNARE:
            osc.type = 'triangle'; osc.frequency.setValueAtTime(200, time);
            const toneGain = ctx.createGain(); toneGain.gain.setValueAtTime(baseVol * 0.5, time); toneGain.gain.exponentialRampToValueAtTime(0.001, time + 0.2);
            osc.connect(toneGain); toneGain.connect(masterGain);
            const noiseFilter = ctx.createBiquadFilter(); noiseFilter.type = 'highpass'; noiseFilter.frequency.value = 1000;
            const noiseGain = ctx.createGain(); noiseGain.gain.setValueAtTime(baseVol * (isIndustrial ? 1.5 : 0.8), time); noiseGain.gain.exponentialRampToValueAtTime(0.001, time + 0.25);
            noise.connect(noiseFilter); noiseFilter.connect(noiseGain); noiseGain.connect(masterGain);
            osc.start(time); osc.stop(time + 0.2); noise.start(time); noise.stop(time + 0.3); break;
        case DrumInstrument.HIHAT_CLOSED: case DrumInstrument.HIHAT_OPEN:
            const hp = ctx.createBiquadFilter(); hp.type = 'highpass'; hp.frequency.value = isIndustrial ? 3000 : 7000;
            const dur = inst === DrumInstrument.HIHAT_OPEN ? 0.3 : 0.05;
            masterGain.gain.setValueAtTime(baseVol * 0.4, time); masterGain.gain.exponentialRampToValueAtTime(0.001, time + dur);
            noise.connect(hp); hp.connect(masterGain); noise.start(time); noise.stop(time + dur); break;
        default: // Toms / Crash
            osc.type = 'sine'; const freq = inst === DrumInstrument.TOM_LOW ? 80 : 200;
            osc.frequency.setValueAtTime(freq, time); osc.frequency.exponentialRampToValueAtTime(freq * 0.5, time + 0.3);
            masterGain.gain.setValueAtTime(baseVol, time); masterGain.gain.exponentialRampToValueAtTime(0.001, time + 0.3);
            osc.connect(masterGain); osc.start(time); osc.stop(time + 0.3); break;
    }
  }

  public trigger(instrument: DrumInstrument, time: number, velocity: number) {
    // ğŸ”¥ å¦‚æœ Context æ„å¤–æ²¡äº†ï¼Œé‡æ–° init ä¸€ä¸‹
    if (!this.ctx) { 
        this.init(); 
        return; 
    }
    this.scheduleNoteGraph(this.ctx, this.masterChain!, instrument, time, velocity, this.currentKit);
  }

  public async exportWav(pattern: GeneratedPattern): Promise<Blob> {
      await this.init(); // å¯¼å‡ºæ—¶è¿˜æ˜¯éœ€è¦ await ä¸€ä¸‹ï¼Œç¡®ä¿ç¯å¢ƒæ²¡é—®é¢˜
      // ç®€åŒ–å¯¼å‡º...
      return new Blob([], { type: "audio/wav" }); 
  }
}

export const audioEngine = new AudioEngine();